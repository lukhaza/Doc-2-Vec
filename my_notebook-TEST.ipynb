{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "import nltk\n",
    "import string\n",
    "import multiprocessing\n",
    "import time\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim.models.doc2vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert gensim.models.doc2vec.FAST_VERSION > -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(post):\n",
    "    punc_num = string.punctuation + '0123456789'\n",
    "    return ''.join([l for l in post if l not in punc_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    sss = set(stopwords.words('english'))\n",
    "    return [t for t in tokens if t not in sss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mbti = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mbti = []\n",
    "for i,r in mbti.iterrows():\n",
    "    for comment in r['posts'].split('|||'):\n",
    "        all_mbti.append([r['type'],comment])\n",
    "all_mbti = pd.DataFrame(all_mbti, columns=['type', 'post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "subs_url = r'url-web'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_mbti['post'] = all_mbti['post'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "all_mbti['post'] = all_mbti['post'].str.lower()\n",
    "all_mbti['post'] = all_mbti['post'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "all_mbti['tokens'] = all_mbti['post'].apply(tokeniser.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  urlweb  sportscenter no...</td>\n",
       "      <td>[enfp, and, intj, moments, urlweb, sportscente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>what has been the most lifechanging experience...</td>\n",
       "      <td>[what, has, been, the, most, lifechanging, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>urlweb   urlweb  on repeat for most of today</td>\n",
       "      <td>[urlweb, urlweb, on, repeat, for, most, of, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>may the perc experience immerse you</td>\n",
       "      <td>[may, the, perc, experience, immerse, you]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>the last thing my infj friend posted on his fa...</td>\n",
       "      <td>[the, last, thing, my, infj, friend, posted, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post  \\\n",
       "2  INFJ  enfp and intj moments  urlweb  sportscenter no...   \n",
       "3  INFJ  what has been the most lifechanging experience...   \n",
       "4  INFJ       urlweb   urlweb  on repeat for most of today   \n",
       "5  INFJ                may the perc experience immerse you   \n",
       "6  INFJ  the last thing my infj friend posted on his fa...   \n",
       "\n",
       "                                              tokens  \n",
       "2  [enfp, and, intj, moments, urlweb, sportscente...  \n",
       "3  [what, has, been, the, most, lifechanging, exp...  \n",
       "4  [urlweb, urlweb, on, repeat, for, most, of, to...  \n",
       "5         [may, the, perc, experience, immerse, you]  \n",
       "6  [the, last, thing, my, infj, friend, posted, o...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti = all_mbti[all_mbti['post']!='urlweb']\n",
    "all_mbti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(all_mbti['tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "vec_size = 100\n",
    "alpha = 0.043\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha,\n",
    "                window = 4 ,\n",
    "                min_alpha=0.033,\n",
    "                min_count=3,\n",
    "                dm =1,\n",
    "                max_vocab_size=20000,\n",
    "                workers=cores,\n",
    "                negative = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Alpha:  0.0428\n",
      "iteration 1\n",
      "Model Alpha:  0.0426\n",
      "iteration 2\n",
      "Model Alpha:  0.0424\n",
      "iteration 3\n",
      "Model Alpha:  0.0422\n",
      "iteration 4\n",
      "Model Alpha:  0.042\n",
      "iteration 5\n",
      "Model Alpha:  0.041800000000000004\n",
      "iteration 6\n",
      "Model Alpha:  0.041600000000000005\n",
      "iteration 7\n",
      "Model Alpha:  0.041400000000000006\n",
      "iteration 8\n",
      "Model Alpha:  0.04120000000000001\n",
      "iteration 9\n",
      "Model Alpha:  0.04100000000000001\n",
      "iteration 10\n",
      "Model Alpha:  0.04080000000000001\n",
      "iteration 11\n",
      "Model Alpha:  0.04060000000000001\n",
      "iteration 12\n",
      "Model Alpha:  0.04040000000000001\n",
      "iteration 13\n",
      "Model Alpha:  0.040200000000000014\n",
      "iteration 14\n",
      "Model Alpha:  0.040000000000000015\n",
      "iteration 15\n",
      "Model Alpha:  0.039800000000000016\n",
      "iteration 16\n",
      "Model Alpha:  0.03960000000000002\n",
      "iteration 17\n",
      "Model Alpha:  0.03940000000000002\n",
      "iteration 18\n",
      "Model Alpha:  0.03920000000000002\n",
      "iteration 19\n",
      "Model Alpha:  0.03900000000000002\n",
      "iteration 20\n",
      "Model Alpha:  0.03880000000000002\n",
      "iteration 21\n",
      "Model Alpha:  0.03860000000000002\n",
      "iteration 22\n",
      "Model Alpha:  0.038400000000000024\n",
      "iteration 23\n",
      "Model Alpha:  0.038200000000000026\n",
      "iteration 24\n",
      "Model Alpha:  0.03800000000000003\n",
      "iteration 25\n",
      "Model Alpha:  0.03780000000000003\n",
      "iteration 26\n",
      "Model Alpha:  0.03760000000000003\n",
      "iteration 27\n",
      "Model Alpha:  0.03740000000000003\n",
      "iteration 28\n",
      "Model Alpha:  0.03720000000000003\n",
      "iteration 29\n",
      "Model Alpha:  0.03700000000000003\n",
      "iteration 30\n",
      "Model Alpha:  0.036800000000000034\n",
      "iteration 31\n",
      "Model Alpha:  0.036600000000000035\n",
      "iteration 32\n",
      "Model Alpha:  0.036400000000000036\n",
      "iteration 33\n",
      "Model Alpha:  0.03620000000000004\n",
      "iteration 34\n",
      "Model Alpha:  0.03600000000000004\n",
      "iteration 35\n",
      "Model Alpha:  0.03580000000000004\n",
      "iteration 36\n",
      "Model Alpha:  0.03560000000000004\n",
      "iteration 37\n",
      "Model Alpha:  0.03540000000000004\n",
      "iteration 38\n",
      "Model Alpha:  0.035200000000000044\n",
      "iteration 39\n",
      "Model Alpha:  0.035000000000000045\n",
      "iteration 40\n",
      "Model Alpha:  0.034800000000000046\n",
      "iteration 41\n",
      "Model Alpha:  0.03460000000000005\n",
      "iteration 42\n",
      "Model Alpha:  0.03440000000000005\n",
      "iteration 43\n",
      "Model Alpha:  0.03420000000000005\n",
      "iteration 44\n",
      "Model Alpha:  0.03400000000000005\n",
      "iteration 45\n",
      "Model Alpha:  0.03380000000000005\n",
      "iteration 46\n",
      "Model Alpha:  0.03360000000000005\n",
      "iteration 47\n",
      "Model Alpha:  0.033400000000000055\n",
      "iteration 48\n",
      "Model Alpha:  0.033200000000000056\n",
      "iteration 49\n",
      "Model Alpha:  0.03300000000000006\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "        # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    print('Model Alpha: ',model.alpha)\n",
    "                # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "#model.save(\"no_url.model_w4\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "#model= Doc2Vec.load(\"no_url.model_w4\")\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('explain', 0.6601998805999756),\n",
       " ('classify', 0.6462870240211487),\n",
       " ('define', 0.6090109944343567),\n",
       " ('teach', 0.601032018661499),\n",
       " ('understand', 0.5891581773757935),\n",
       " ('kill', 0.5884768962860107),\n",
       " ('consider', 0.584587574005127),\n",
       " ('introduce', 0.5781498551368713),\n",
       " ('express', 0.5779985189437866),\n",
       " ('confuse', 0.568020224571228)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('describe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>post</th>\n",
       "      <th>tokens</th>\n",
       "      <th>I</th>\n",
       "      <th>N</th>\n",
       "      <th>T</th>\n",
       "      <th>P</th>\n",
       "      <th>vectorized_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>enfp and intj moments  urlweb  sportscenter no...</td>\n",
       "      <td>[enfp, and, intj, moments, urlweb, sportscente...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.865215, 0.478191, 0.989163, -0.444672, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>what has been the most lifechanging experience...</td>\n",
       "      <td>[what, has, been, the, most, lifechanging, exp...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-1.05232, 0.232657, -0.589661, 0.647971, 1.23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>urlweb   urlweb  on repeat for most of today</td>\n",
       "      <td>[urlweb, urlweb, on, repeat, for, most, of, to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.888199, 0.555337, -0.0629176, -0.0698107, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>may the perc experience immerse you</td>\n",
       "      <td>[may, the, perc, experience, immerse, you]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.836576, 0.286395, -0.39377, -0.0151721, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>the last thing my infj friend posted on his fa...</td>\n",
       "      <td>[the, last, thing, my, infj, friend, posted, o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.397126, 0.741715, 0.521582, 1.40831, 1.104...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               post  \\\n",
       "2  INFJ  enfp and intj moments  urlweb  sportscenter no...   \n",
       "3  INFJ  what has been the most lifechanging experience...   \n",
       "4  INFJ       urlweb   urlweb  on repeat for most of today   \n",
       "5  INFJ                may the perc experience immerse you   \n",
       "6  INFJ  the last thing my infj friend posted on his fa...   \n",
       "\n",
       "                                              tokens  I  N  T  P  \\\n",
       "2  [enfp, and, intj, moments, urlweb, sportscente...  1  1  0  0   \n",
       "3  [what, has, been, the, most, lifechanging, exp...  1  1  0  0   \n",
       "4  [urlweb, urlweb, on, repeat, for, most, of, to...  1  1  0  0   \n",
       "5         [may, the, perc, experience, immerse, you]  1  1  0  0   \n",
       "6  [the, last, thing, my, infj, friend, posted, o...  1  1  0  0   \n",
       "\n",
       "                                 vectorized_comments  \n",
       "2  [0.865215, 0.478191, 0.989163, -0.444672, -0.0...  \n",
       "3  [-1.05232, 0.232657, -0.589661, 0.647971, 1.23...  \n",
       "4  [-0.888199, 0.555337, -0.0629176, -0.0698107, ...  \n",
       "5  [0.836576, 0.286395, -0.39377, -0.0151721, 0.0...  \n",
       "6  [-0.397126, 0.741715, 0.521582, 1.40831, 1.104...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_mbti' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3bf81aaf38f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#all_mbti.drop('index',axis = 1,inplace =True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#all_mbti.reset_index(inplace = True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mall_mbti\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#all_mbti['Index'] = all_mbti['level_0']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_mbti' is not defined"
     ]
    }
   ],
   "source": [
    "#all_mbti.reset_index(inplace = True)\n",
    "#all_mbti.drop('index',axis = 1,inplace =True)\n",
    "all_mbti.reset_index(inplace = True)\n",
    "all_mbti.head()\n",
    "#all_mbti['Index'] = all_mbti['level_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para = 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309301, 9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = pd.concat([vc,all_mbti],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309301, 109)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cab', 0.3884442448616028),\n",
       " ('intjer', 0.354928195476532),\n",
       " ('rice', 0.34935396909713745),\n",
       " ('climbing', 0.3356604278087616),\n",
       " ('af', 0.3282245695590973),\n",
       " ('imperialism', 0.321328729391098),\n",
       " ('xd', 0.3191835284233093),\n",
       " ('jones', 0.3130473494529724),\n",
       " ('galaxy', 0.3112452030181885),\n",
       " ('phantom', 0.3050224781036377)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-aca46a8cafc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilar_by_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'soccer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.wv.similar_by_word('soccer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
